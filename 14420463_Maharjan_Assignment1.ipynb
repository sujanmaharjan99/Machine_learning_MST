{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 242, 'name': 'Energy Efficiency', 'repository_url': 'https://archive.ics.uci.edu/dataset/242/energy+efficiency', 'data_url': 'https://archive.ics.uci.edu/static/public/242/data.csv', 'abstract': 'This study looked into assessing the heating load and cooling load requirements of buildings (that is, energy efficiency) as a function of building parameters.', 'area': 'Computer Science', 'tasks': ['Classification', 'Regression'], 'characteristics': ['Multivariate'], 'num_instances': 768, 'num_features': 8, 'feature_types': ['Integer', 'Real'], 'demographics': [], 'target_col': ['Y1', 'Y2'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2012, 'last_updated': 'Mon Feb 26 2024', 'dataset_doi': '10.24432/C51307', 'creators': ['Athanasios Tsanas', 'Angeliki Xifara'], 'intro_paper': {'ID': 379, 'type': 'NATIVE', 'title': 'Accurate quantitative estimation of energy performance of residential buildings using statistical machine learning tools', 'authors': 'A. Tsanas, Angeliki Xifara', 'venue': 'Energy and Buildings, vol. 49', 'year': 2012, 'journal': None, 'DOI': None, 'URL': 'https://www.semanticscholar.org/paper/Accurate-quantitative-estimation-of-energy-of-using-Tsanas-Xifara/719e65379c5959141180a45f540f707d583b8ce2', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'We perform energy analysis using 12 different building shapes simulated in Ecotect. The buildings differ with respect to the glazing area, the glazing area distribution, and the orientation, amongst other parameters. We simulate various settings as functions of the afore-mentioned characteristics to obtain 768 building shapes. The dataset comprises 768 samples and 8 features, aiming to predict two real valued responses. It can also be used as a multi-class classification problem if the response is rounded to the nearest integer.', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'The dataset contains eight attributes (or features, denoted by X1...X8) and two responses (or outcomes, denoted by y1 and y2). The aim is to use the eight features to predict each of the two responses.\\r\\n\\r\\nSpecifically:\\r\\nX1\\tRelative Compactness\\r\\nX2\\tSurface Area\\r\\nX3\\tWall Area\\r\\nX4\\tRoof Area\\r\\nX5\\tOverall Height\\r\\nX6\\tOrientation\\r\\nX7\\tGlazing Area\\r\\nX8\\tGlazing Area Distribution\\r\\ny1\\tHeating Load\\r\\ny2\\tCooling Load', 'citation': None}}\n",
      "  name     role        type demographic                description units  \\\n",
      "0   X1  Feature  Continuous        None       Relative Compactness  None   \n",
      "1   X2  Feature  Continuous        None               Surface Area  None   \n",
      "2   X3  Feature  Continuous        None                  Wall Area  None   \n",
      "3   X4  Feature  Continuous        None                  Roof Area  None   \n",
      "4   X5  Feature  Continuous        None             Overall Height  None   \n",
      "5   X6  Feature     Integer        None                Orientation  None   \n",
      "6   X7  Feature  Continuous        None               Glazing Area  None   \n",
      "7   X8  Feature     Integer        None  Glazing Area Distribution  None   \n",
      "8   Y1   Target  Continuous        None               Heating Load  None   \n",
      "9   Y2   Target  Continuous        None               Cooling Load  None   \n",
      "\n",
      "  missing_values  \n",
      "0             no  \n",
      "1             no  \n",
      "2             no  \n",
      "3             no  \n",
      "4             no  \n",
      "5             no  \n",
      "6             no  \n",
      "7             no  \n",
      "8             no  \n",
      "9             no  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "energy_efficiency = fetch_ucirepo(id=242) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = energy_efficiency.data.features \n",
    "y = energy_efficiency.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(energy_efficiency.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(energy_efficiency.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_test_split(X, y):\n",
    "    ''' Split the data into train, validation and test datasets using pandas'''\n",
    "    train=int(X.shape[0]*0.7)\n",
    "    valid=int(X.shape[0]*0.1)\n",
    "    test=int(X.shape[0]*0.2)\n",
    "    print(\"Data amounts to training data {}, validation data {} and testing data {}. \".format(train, valid, test))\n",
    "\n",
    "    X_df=pd.DataFrame(X, dtype=float)\n",
    "    X_df.insert(0, 'W0', 1)\n",
    "    X_train=X_df.iloc[0:train,:].values\n",
    "    X_valid=X_df.iloc[train:train+valid,:].values\n",
    "    X_test=X_df.iloc[train+valid:,:].values\n",
    "    y_df=pd.DataFrame(y, dtype=float)\n",
    "    y_train=y_df.iloc[0:train,:].values\n",
    "    y_valid=y_df.iloc[train:train+valid,:].values\n",
    "    y_test=y_df.iloc[train+valid:,:].values\n",
    "    \n",
    "    return X_train, X_valid, X_test, y_train, y_valid, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_hat_lin_calc(X_train, y_train):\n",
    "    w_hat=np.linalg.inv(X_train.T @ X_train) @ X_train.T @ y_train\n",
    "    return w_hat\n",
    "\n",
    "def w_hat_lin_calc_pseudo(X_train, y_train):\n",
    "    w_hat=np.linalg.pinv(X_train.T @ X_train) @ X_train.T @ y_train\n",
    "    return w_hat\n",
    "\n",
    "def w_hat_ridge_calc(X_train, y_train,lamb):\n",
    "    n_features=X_train.shape[1]\n",
    "    w_hat=np.linalg.inv(X_train.T @ X_train + lamb*np.eye(n_features)) @ X_train.T @ y_train\n",
    "    return w_hat\n",
    "\n",
    "def predict(X, w_hat):\n",
    "    y_predict=X @ w_hat\n",
    "    return y_predict\n",
    "\n",
    "def compare(y_test, y_predict,n):\n",
    "    mae_i = np.mean(np.abs(y_test - y_predict))\n",
    "    mse_i = np.mean((y_test - y_predict) ** 2)\n",
    "    rmse_i = np.sqrt(mse_i)\n",
    "    print(\"For the Y{}, the MAE is {:.3f}, MSE is {:.3f} and RMSE is {:.3f}.\"\n",
    "        .format(n, mae_i, mse_i, rmse_i))\n",
    "    return\n",
    "\n",
    "def standardize(X):\n",
    "    X_std=(X - np.mean(X)) / np.std(X)\n",
    "    return X_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data amounts to training data 537, validation data 76 and testing data 153. \n",
      "###TRAINING DATASET RESULTS###\n",
      "-------------------------\n",
      "Ridge Regression Results on Training Data:\n",
      "-------------------------\n",
      "For the Y1, the MAE is 2.125, MSE is 9.064 and RMSE is 3.011.\n",
      "For the Y2, the MAE is 2.318, MSE is 10.678 and RMSE is 3.268.\n",
      "-------------------------\n",
      "###VALIDATION DATASET RESULTS###\n",
      "-------------------------\n",
      "Linear Regression Results using np.linalg.inv:\n",
      "-------------------------\n",
      "For the Y1, the MAE is 17.212, MSE is 460.190 and RMSE is 21.452.\n",
      "For the Y2, the MAE is 20.092, MSE is 636.090 and RMSE is 25.221.\n",
      "-------------------------\n",
      "Data amounts to training data 537, validation data 76 and testing data 153. \n",
      "-------------------------\n",
      "Linear Regression Results using standardized data:\n",
      "-------------------------\n",
      "For the Y1, the MAE is 4.677, MSE is 31.515 and RMSE is 5.614.\n",
      "For the Y2, the MAE is 5.319, MSE is 40.053 and RMSE is 6.329.\n",
      "-------------------------\n",
      "-------------------------\n",
      "Linear Regression Results using np.linalg.pinv:\n",
      "-------------------------\n",
      "For the Y1, the MAE is 2.532, MSE is 10.446 and RMSE is 3.232.\n",
      "For the Y2, the MAE is 2.562, MSE is 12.038 and RMSE is 3.470.\n",
      "-------------------------\n",
      "-------------------------\n",
      "Ridge Regression Results of validation data:\n",
      "-------------------------\n",
      "For the Y1, the MAE is 2.345, MSE is 10.347 and RMSE is 3.217.\n",
      "For the Y2, the MAE is 2.423, MSE is 11.971 and RMSE is 3.460.\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, X_test, y_train, y_valid, y_test=train_valid_test_split(X,y)\n",
    "w_hat_rid1=w_hat_ridge_calc(X_train, y_train[:, 0],1)\n",
    "w_hat_rid2=w_hat_ridge_calc(X_train, y_train[:, 1],1)\n",
    "y_predict_ridge_train1=predict(X_train, w_hat_rid1)\n",
    "y_predict_ridge_train2=predict(X_train, w_hat_rid2)\n",
    "print(\"###TRAINING DATASET RESULTS###\")\n",
    "print(\"-------------------------\")\n",
    "print(\"Ridge Regression Results on Training Data:\")\n",
    "print(\"-------------------------\")\n",
    "compare(y_train[:, 0], y_predict_ridge_train1,1)\n",
    "compare(y_train[:, 1], y_predict_ridge_train2,2)\n",
    "\n",
    "print(\"-------------------------\")\n",
    "print(\"###VALIDATION DATASET RESULTS###\")\n",
    "# validation dataset calculation and results\n",
    "\n",
    "w_hat_lin1=w_hat_lin_calc(X_train, y_train[:, 0])\n",
    "w_hat_lin2=w_hat_lin_calc(X_train, y_train[:, 1])\n",
    "y_predict_linear1=predict(X_valid, w_hat_lin1)\n",
    "y_predict_linear2=predict(X_valid, w_hat_lin2)\n",
    "print(\"-------------------------\")\n",
    "print(\"Linear Regression Results using np.linalg.inv:\")\n",
    "print(\"-------------------------\")\n",
    "compare(y_valid[:, 0], y_predict_linear1,1)\n",
    "compare(y_valid[:, 1], y_predict_linear2,2)\n",
    "print(\"-------------------------\")\n",
    "\n",
    "X_train, X_valid, X_test, y_train, y_valid, y_test=train_valid_test_split(X,y)\n",
    "w_hat_lin_std1=w_hat_lin_calc(standardize(X_train), y_train[:, 0])\n",
    "w_hat_lin_std2=w_hat_lin_calc(standardize(X_train), y_train[:, 1])\n",
    "y_predict_linear1=predict(standardize(X_valid), w_hat_lin_std1)\n",
    "y_predict_linear2=predict(standardize(X_valid), w_hat_lin_std2)\n",
    "print(\"-------------------------\")\n",
    "print(\"Linear Regression Results using standardized data:\")\n",
    "print(\"-------------------------\")\n",
    "compare(y_valid[:, 0], y_predict_linear1,1)\n",
    "compare(y_valid[:, 1], y_predict_linear2,2)\n",
    "print(\"-------------------------\")\n",
    "\n",
    "w_hat_lin_calc_pseudo1=w_hat_lin_calc_pseudo(X_train, y_train[:, 0])\n",
    "w_hat_lin_calc_pseudo2=w_hat_lin_calc_pseudo(X_train, y_train[:, 1])\n",
    "y_predict_linear1=predict(X_valid, w_hat_lin_calc_pseudo1)\n",
    "y_predict_linear2=predict(X_valid, w_hat_lin_calc_pseudo2)\n",
    "print(\"-------------------------\")\n",
    "print(\"Linear Regression Results using np.linalg.pinv:\")\n",
    "print(\"-------------------------\")\n",
    "compare(y_valid[:, 0], y_predict_linear1,1)\n",
    "compare(y_valid[:, 1], y_predict_linear2,2)\n",
    "print(\"-------------------------\") \n",
    "\n",
    "\n",
    "print(\"-------------------------\")\n",
    "y_predict_ridge1=predict(X_valid, w_hat_rid1)\n",
    "y_predict_ridge2=predict(X_valid, w_hat_rid2)\n",
    "\n",
    "print(\"Ridge Regression Results of validation data:\")\n",
    "print(\"-------------------------\")\n",
    "compare(y_valid[:, 0], y_predict_ridge1,1)\n",
    "compare(y_valid[:, 1], y_predict_ridge2,2)\n",
    "print(\"-------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "###TEST DATASET RESULTS###\n",
      "-------------------------\n",
      "Linear Regression Results using np.linalg.inv for test dataset:\n",
      "-------------------------\n",
      "For the Y1, the MAE is 18.340, MSE is 537.173 and RMSE is 23.177.\n",
      "For the Y2, the MAE is 21.310, MSE is 744.193 and RMSE is 27.280.\n",
      "-------------------------\n",
      "-------------------------\n",
      "Linear Regression Results using standardized data for test dataset:\n",
      "-------------------------\n",
      "For the Y1, the MAE is 6.698, MSE is 64.264 and RMSE is 8.017.\n",
      "For the Y2, the MAE is 6.875, MSE is 70.735 and RMSE is 8.410.\n",
      "-------------------------\n",
      "-------------------------\n",
      "Linear Regression Results using np.linalg.pinv for test dataset:\n",
      "-------------------------\n",
      "For the Y1, the MAE is 2.750, MSE is 10.890 and RMSE is 3.300.\n",
      "For the Y2, the MAE is 2.585, MSE is 10.836 and RMSE is 3.292.\n",
      "-------------------------\n",
      "-------------------------\n",
      "Ridge Regression Results for test dataset:\n",
      "-------------------------\n",
      "For the Y1, the MAE is 2.186, MSE is 8.362 and RMSE is 2.892.\n",
      "For the Y2, the MAE is 2.263, MSE is 9.793 and RMSE is 3.129.\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------------------\")\n",
    "print(\"###TEST DATASET RESULTS###\")\n",
    "# testing dataset calculation and results   \n",
    "y_predict_linear1=predict(X_test, w_hat_lin1)\n",
    "y_predict_linear2=predict(X_test, w_hat_lin2)\n",
    "print(\"-------------------------\")\n",
    "print(\"Linear Regression Results using np.linalg.inv for test dataset:\")\n",
    "print(\"-------------------------\")\n",
    "compare(y_test[:, 0], y_predict_linear1,1)\n",
    "compare(y_test[:, 1], y_predict_linear2,2)\n",
    "print(\"-------------------------\")\n",
    "y_predict_linear1=predict(standardize(X_test), w_hat_lin_std1)\n",
    "y_predict_linear2=predict(standardize(X_test), w_hat_lin_std2)\n",
    "print(\"-------------------------\")\n",
    "print(\"Linear Regression Results using standardized data for test dataset:\")\n",
    "print(\"-------------------------\")\n",
    "compare(y_test[:, 0], y_predict_linear1,1)\n",
    "compare(y_test[:, 1], y_predict_linear2,2)\n",
    "print(\"-------------------------\")\n",
    "y_predict_linear1=predict(X_test, w_hat_lin_calc_pseudo1)\n",
    "y_predict_linear2=predict(X_test, w_hat_lin_calc_pseudo2)\n",
    "print(\"-------------------------\")\n",
    "print(\"Linear Regression Results using np.linalg.pinv for test dataset:\")\n",
    "print(\"-------------------------\")\n",
    "compare(y_test[:, 0], y_predict_linear1,1)\n",
    "compare(y_test[:, 1], y_predict_linear2,2)\n",
    "print(\"-------------------------\")\n",
    "print(\"-------------------------\")\n",
    "y_predict_ridge1=predict(X_test, w_hat_rid1)\n",
    "y_predict_ridge2=predict(X_test, w_hat_rid2)\n",
    "print(\"Ridge Regression Results for test dataset:\")\n",
    "print(\"-------------------------\")\n",
    "compare(y_test[:, 0], y_predict_ridge1,1)\n",
    "compare(y_test[:, 1], y_predict_ridge2,2)\n",
    "print(\"-------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "Sklearn Linear Regression Results:\n",
      "--------------\n",
      "For the Y1, the MAE is 2.668, MSE is 10.863 and RMSE is 3.296.\n",
      "--------------\n",
      "Sklearn Ridge Regression Results:\n",
      "--------------\n",
      "For the Y2, the MAE is 2.309, MSE is 9.354 and RMSE is 3.058.\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "X_df=pd.DataFrame(X)\n",
    "train=int(X.shape[0]*0.7)\n",
    "valid=int(X.shape[0]*0.1)\n",
    "test=int(X.shape[0]*0.2)\n",
    "X_train=X_df.iloc[0:train,:].values\n",
    "X_valid=X_df.iloc[train:train+valid,:].values\n",
    "X_test=X_df.iloc[train+valid:,:].values\n",
    "y_df=pd.DataFrame(y)\n",
    "y_train=y_df.iloc[0:train,:].values\n",
    "y_valid=y_df.iloc[train:train+valid,:].values\n",
    "y_test=y_df.iloc[train+valid:,:].values\n",
    "LR_model=LinearRegression()\n",
    "LR_model.fit(X_train, y_train)\n",
    "y_predict_sklearn=LR_model.predict(X_test)\n",
    "RR_model=Ridge(alpha=1)\n",
    "RR_model.fit(X_train, y_train)\n",
    "y_predict_ridge_sklearn=RR_model.predict(X_test)\n",
    "\n",
    "print(\"--------------\")\n",
    "print(\"Sklearn Linear Regression Results:\")\n",
    "print(\"--------------\")\n",
    "compare(y_test, y_predict_sklearn,1)\n",
    "\n",
    "print(\"--------------\")\n",
    "print(\"Sklearn Ridge Regression Results:\")\n",
    "print(\"--------------\")\n",
    "compare(y_test, y_predict_ridge_sklearn,2)\n",
    "print(\"-------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
