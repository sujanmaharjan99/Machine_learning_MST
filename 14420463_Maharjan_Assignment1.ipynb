{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 242, 'name': 'Energy Efficiency', 'repository_url': 'https://archive.ics.uci.edu/dataset/242/energy+efficiency', 'data_url': 'https://archive.ics.uci.edu/static/public/242/data.csv', 'abstract': 'This study looked into assessing the heating load and cooling load requirements of buildings (that is, energy efficiency) as a function of building parameters.', 'area': 'Computer Science', 'tasks': ['Classification', 'Regression'], 'characteristics': ['Multivariate'], 'num_instances': 768, 'num_features': 8, 'feature_types': ['Integer', 'Real'], 'demographics': [], 'target_col': ['Y1', 'Y2'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2012, 'last_updated': 'Mon Feb 26 2024', 'dataset_doi': '10.24432/C51307', 'creators': ['Athanasios Tsanas', 'Angeliki Xifara'], 'intro_paper': {'ID': 379, 'type': 'NATIVE', 'title': 'Accurate quantitative estimation of energy performance of residential buildings using statistical machine learning tools', 'authors': 'A. Tsanas, Angeliki Xifara', 'venue': 'Energy and Buildings, vol. 49', 'year': 2012, 'journal': None, 'DOI': None, 'URL': 'https://www.semanticscholar.org/paper/Accurate-quantitative-estimation-of-energy-of-using-Tsanas-Xifara/719e65379c5959141180a45f540f707d583b8ce2', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'We perform energy analysis using 12 different building shapes simulated in Ecotect. The buildings differ with respect to the glazing area, the glazing area distribution, and the orientation, amongst other parameters. We simulate various settings as functions of the afore-mentioned characteristics to obtain 768 building shapes. The dataset comprises 768 samples and 8 features, aiming to predict two real valued responses. It can also be used as a multi-class classification problem if the response is rounded to the nearest integer.', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'The dataset contains eight attributes (or features, denoted by X1...X8) and two responses (or outcomes, denoted by y1 and y2). The aim is to use the eight features to predict each of the two responses.\\r\\n\\r\\nSpecifically:\\r\\nX1\\tRelative Compactness\\r\\nX2\\tSurface Area\\r\\nX3\\tWall Area\\r\\nX4\\tRoof Area\\r\\nX5\\tOverall Height\\r\\nX6\\tOrientation\\r\\nX7\\tGlazing Area\\r\\nX8\\tGlazing Area Distribution\\r\\ny1\\tHeating Load\\r\\ny2\\tCooling Load', 'citation': None}}\n",
      "  name     role        type demographic                description units  \\\n",
      "0   X1  Feature  Continuous        None       Relative Compactness  None   \n",
      "1   X2  Feature  Continuous        None               Surface Area  None   \n",
      "2   X3  Feature  Continuous        None                  Wall Area  None   \n",
      "3   X4  Feature  Continuous        None                  Roof Area  None   \n",
      "4   X5  Feature  Continuous        None             Overall Height  None   \n",
      "5   X6  Feature     Integer        None                Orientation  None   \n",
      "6   X7  Feature  Continuous        None               Glazing Area  None   \n",
      "7   X8  Feature     Integer        None  Glazing Area Distribution  None   \n",
      "8   Y1   Target  Continuous        None               Heating Load  None   \n",
      "9   Y2   Target  Continuous        None               Cooling Load  None   \n",
      "\n",
      "  missing_values  \n",
      "0             no  \n",
      "1             no  \n",
      "2             no  \n",
      "3             no  \n",
      "4             no  \n",
      "5             no  \n",
      "6             no  \n",
      "7             no  \n",
      "8             no  \n",
      "9             no  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "energy_efficiency = fetch_ucirepo(id=242) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = energy_efficiency.data.features \n",
    "y = energy_efficiency.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(energy_efficiency.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(energy_efficiency.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_test_split(X, y):\n",
    "    ''' Split the data into train, validation and test datasets using pandas'''\n",
    "    train=int(X.shape[0]*0.7)\n",
    "    valid=int(X.shape[0]*0.2)\n",
    "    test=int(X.shape[0]*0.1)\n",
    "    print(\"Data amounts to training data {}, validation data {} and testing data {}. \".format(train, valid, test))\n",
    "\n",
    "    X_df=pd.DataFrame(X)\n",
    "    X_df.insert(0, 'W0', 1)\n",
    "    X_train=X_df.iloc[0:train,:].values\n",
    "    X_valid=X_df.iloc[train:train+valid,:].values\n",
    "    X_test=X_df.iloc[train+valid:,:].values\n",
    "    y_df=pd.DataFrame(y)\n",
    "    y_train=y_df.iloc[0:train,:].values\n",
    "    y_valid=y_df.iloc[train:train+valid,:].values\n",
    "    y_test=y_df.iloc[train+valid:,:].values\n",
    "    \n",
    "    return X_train, X_valid, X_test, y_train, y_valid, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_inverse(np_matrix):\n",
    "    ''' Compute the matrix inverse using numpy'''\n",
    "    np_matrix_inv=np.linalg.inv(np_matrix)\n",
    "    return np_matrix_inv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data amounts to training data 537, validation data 153 and testing data 76. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.000e+00, 9.800e-01, 5.145e+02, ..., 2.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [1.000e+00, 9.800e-01, 5.145e+02, ..., 3.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [1.000e+00, 9.800e-01, 5.145e+02, ..., 4.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       ...,\n",
       "       [1.000e+00, 9.000e-01, 5.635e+02, ..., 4.000e+00, 4.000e-01,\n",
       "        1.000e+00],\n",
       "       [1.000e+00, 9.000e-01, 5.635e+02, ..., 5.000e+00, 4.000e-01,\n",
       "        1.000e+00],\n",
       "       [1.000e+00, 8.600e-01, 5.880e+02, ..., 2.000e+00, 4.000e-01,\n",
       "        1.000e+00]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid, X_test, y_train, y_valid, y_test=train_valid_test_split(X,y)\n",
    "X_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
